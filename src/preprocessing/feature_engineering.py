"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è:
- –°–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
- –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- –°–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML –º–æ–¥–µ–ª–µ–π
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π
from .indicators import TechnicalIndicators
from .target_creation import TargetCreator
from .data_balancing import DataBalancer
from .multi_timeframe import MultiTimeframeProcessor
from .adaptive_indicators import AdaptiveIndicatorSelector

# –ò–º–ø–æ—Ä—Ç –Ω–æ–≤—ã—Ö –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–æ–¥—É–ª–µ–π
try:
    from .advanced_features import AdvancedFeatureEngine
    from ..data_collection.sentiment_collector import SentimentCollector
except ImportError:
    # Fallback –¥–ª—è —Å–ª—É—á–∞–µ–≤ –∑–∞–ø—É—Å–∫–∞ –Ω–µ –∏–∑ –ø–∞–∫–µ—Ç–∞
    try:
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
        from preprocessing.advanced_features import AdvancedFeatureEngine
        from data_collection.sentiment_collector import SentimentCollector
    except ImportError:
        AdvancedFeatureEngine = None
        SentimentCollector = None

class FeatureEngineer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    - –û–±—Ä–∞–±–æ—Ç–∫—É –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    - –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö
    - –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    - –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
    """
    
    def __init__(self, config: Dict = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–∂–µ–Ω–µ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        self.config = config or {}
        self.logger = logger.bind(name="FeatureEngineer")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.indicators_config = self.config.get('indicators', {})
        self.target_config = self.config.get('target_creation', {})
        self.balancing_config = self.config.get('data_balancing', {})
        self.multi_tf_config = self.config.get('multi_timeframe', {})
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.indicators = TechnicalIndicators(self.indicators_config)
        self.target_creator = TargetCreator(self.target_config)
        self.balancer = DataBalancer(self.balancing_config)
        self.multi_tf_processor = MultiTimeframeProcessor(self.multi_tf_config)
        
        # –ù–û–í–û–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        self.adaptive_selector = AdaptiveIndicatorSelector(self.config.get('adaptive_indicators', {}))
        
        # –ù–û–í–û–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–æ–¥—É–ª–µ–π
        advanced_config = self.config.get('advanced_features', {})
        
        if AdvancedFeatureEngine and advanced_config.get('enabled', False):
            self.advanced_engine = AdvancedFeatureEngine(advanced_config)
        else:
            self.advanced_engine = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è simplified sentiment collector (—Ç–æ–ª—å–∫–æ Bybit)
        sentiment_config = advanced_config.get('api_keys', {}) if advanced_config else {}
        
        if SentimentCollector and advanced_config.get('enabled', False):
            self.sentiment_collector = SentimentCollector(sentiment_config)
        else:
            self.sentiment_collector = None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.prediction_horizons = {
            '5m': 12,   # 12 —Å–≤–µ—á–µ–π –¥–ª—è 5-–º–∏–Ω—É—Ç–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            '15m': 10,  # 10 —Å–≤–µ—á–µ–π –¥–ª—è 15-–º–∏–Ω—É—Ç–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            '1h': 8,    # 8 —Å–≤–µ—á–µ–π –¥–ª—è —á–∞—Å–æ–≤–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            '4h': 6,    # 6 —Å–≤–µ—á–µ–π –¥–ª—è 4-—á–∞—Å–æ–≤–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            '1d': 5     # 5 —Å–≤–µ—á–µ–π –¥–ª—è –¥–Ω–µ–≤–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_stats = {
            'total_features': 0,
            'timeframes_processed': 0,
            'balance_ratio_before': 0,
            'balance_ratio_after': 0,
            'target_distribution': {},
            'feature_importance': {},
            'processing_time': 0
        }
        
        # –§–ª–∞–≥ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        self._use_cached_indicators = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
        
        self.logger.info("FeatureEngineer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def process_single_timeframe(self, df: pd.DataFrame, symbol: str, 
                                timeframe: str = '5m', use_adaptive: bool = True) -> Optional[pd.DataFrame]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã—Ö
            use_adaptive: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        
        Returns:
            DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol} –Ω–∞ {timeframe}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            prediction_horizon = self.prediction_horizons.get(timeframe, 12)
            self.logger.info(f"–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {prediction_horizon} —Å–≤–µ—á–µ–π")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
            processed_df = df.copy()
            
            # –ù–û–í–û–ï: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if use_adaptive and self.config.get('adaptive_indicators', {}).get('enabled', True):
                self.logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å
                force_recalculate = not self._use_cached_indicators
                
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏
                optimization_results = self.adaptive_selector.optimize_indicators(
                    processed_df, timeframe, force_recalculate=force_recalculate
                )
                
                if optimization_results and 'best_combination' in optimization_results:
                    self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –ª—É—á—à–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {optimization_results['best_combination']}")
                    processed_df = self.adaptive_selector.add_best_indicators(processed_df, timeframe)
                else:
                    self.logger.warning("‚ö†Ô∏è –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
                    processed_df = self.indicators.add_all_indicators(processed_df)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                self.logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
                processed_df = self.indicators.add_all_indicators(processed_df)
            
            # –ù–û–í–û–ï: –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º
            processed_df = self._create_target_with_horizon(processed_df, prediction_horizon)
            
            # –ù–û–í–û–ï: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            processed_df = self._add_horizon_based_features(processed_df, prediction_horizon)
            
            # –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ–º simplified sentiment features (—Ç–æ–ª—å–∫–æ Bybit)
            if self.sentiment_collector is not None:
                processed_df = self._add_simplified_sentiment_features(processed_df)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            initial_rows = len(processed_df)
            processed_df = processed_df.dropna()
            removed_rows = initial_rows - len(processed_df)
            
            if removed_rows > 0:
                self.logger.warning(f"–£–¥–∞–ª–µ–Ω–æ {removed_rows} —Å—Ç—Ä–æ–∫ —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            if len(processed_df) < 100:
                self.logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(processed_df)} —Å—Ç—Ä–æ–∫")
                return None
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.processing_stats['total_features'] = len(processed_df.columns)
            self.processing_stats['balance_ratio_before'] = self._calculate_balance_ratio(processed_df)
            
            self.logger.info(f"–ò–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {processed_df.shape}")
            
            return processed_df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}: {e}")
            return None
    
    def _create_target_with_horizon(self, df: pd.DataFrame, horizon: int) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å –∑–∞–¥–∞–Ω–Ω—ã–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            horizon: –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ —Å–≤–µ—á–∞—Ö
            
        Returns:
            DataFrame —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        """
        try:
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –±—É–¥—É—â–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
            future_returns = df['close'].shift(-horizon) / df['close'] - 1
            
            # –ù–û–í–û–ï: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            volatility_multipliers = self._calculate_adaptive_volatility_multipliers(df)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            volatility = df['close'].pct_change().rolling(20).std()
            fall_threshold = -volatility * volatility_multipliers['fall']
            rise_threshold = volatility * volatility_multipliers['rise']
            
            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            target = pd.Series(1, index=df.index)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–æ–∫–æ–≤–∏–∫
            
            # –ü–∞–¥–µ–Ω–∏–µ
            target[future_returns < fall_threshold] = 0
            
            # –†–æ—Å—Ç
            target[future_returns > rise_threshold] = 2
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            df['target'] = target
            
            # –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ
            df['prediction_horizon'] = horizon
            
            self.logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º {horizon} —Å–≤–µ—á–µ–π")
            self.logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {target.value_counts().to_dict()}")
            
            return df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: {e}")
            return df
    
    def _calculate_adaptive_volatility_multipliers(self, data: pd.DataFrame) -> Dict[str, pd.Series]:
        """
        –†–∞—Å—á–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –º–Ω–æ–∂–∏—Ç–µ–ª–µ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π.
        
        Args:
            data: –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–Ω–æ–∂–∏—Ç–µ–ª—è–º–∏ –¥–ª—è –ø–∞–¥–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞
        """
        try:
            # –ë–∞–∑–æ–≤—ã–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏
            base_fall_multiplier = 1.5
            base_rise_multiplier = 1.5
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            returns = data['close'].pct_change()
            
            # 1. –¢–µ–∫—É—â–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π
            current_vol = returns.rolling(20).std()
            historical_vol = returns.rolling(100).std()
            vol_ratio = current_vol / historical_vol
            
            # 2. –¢—Ä–µ–Ω–¥ —Ä—ã–Ω–∫–∞
            short_ma = data['close'].rolling(20).mean()
            long_ma = data['close'].rolling(50).mean()
            trend_strength = (short_ma - long_ma) / long_ma
            
            # 3. –ê—Å–∏–º–º–µ—Ç—Ä–∏—è –¥–≤–∏–∂–µ–Ω–∏–π (–±—ã—á–∏–π/–º–µ–¥–≤–µ–∂–∏–π —Ä—ã–Ω–æ–∫)
            positive_returns = returns[returns > 0]
            negative_returns = returns[returns < 0]
            
            if len(positive_returns) > 0 and len(negative_returns) > 0:
                pos_vol = positive_returns.rolling(20).std()
                neg_vol = negative_returns.rolling(20).std()
                asymmetry_ratio = pos_vol / neg_vol
                # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –æ–±—â–µ–º—É –∏–Ω–¥–µ–∫—Å—É
                asymmetry_ratio = asymmetry_ratio.reindex(data.index).fillna(1.0)
            else:
                asymmetry_ratio = pd.Series(1.0, index=data.index)
            
            # 4. –û–±—ä–µ–º–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            volume_ma = data['volume'].rolling(20).mean()
            volume_ratio = data['volume'] / volume_ma
            volume_ratio = volume_ratio.fillna(1.0)
            
            # 5. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å —Ä—ã–Ω–∫–∞)
            vol_of_vol = current_vol.rolling(20).std()
            vol_of_vol_normalized = vol_of_vol / current_vol
            vol_of_vol_normalized = vol_of_vol_normalized.fillna(0.3)  # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö
            vol_ratio = vol_ratio.fillna(1.0)
            trend_strength = trend_strength.fillna(0.0)
            
            # –ù–û–í–û–ï: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
            fall_multiplier = pd.Series(base_fall_multiplier, index=data.index)
            rise_multiplier = pd.Series(base_rise_multiplier, index=data.index)
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            vol_adjustment = np.where(vol_ratio > 1.2, 0.8,  # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å - —Å–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥–∏
                            np.where(vol_ratio < 0.8, 1.3,   # –ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å - –ø–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥–∏
                            1.0))  # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–∞
            trend_adjustment = np.where(trend_strength > 0.02, 1.1,  # –°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
                              np.where(trend_strength < -0.02, 0.9,  # –°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
                              1.0))  # –ë–æ–∫–æ–≤–æ–π —Ç—Ä–µ–Ω–¥
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏
            asymmetry_adjustment = np.where(asymmetry_ratio > 1.1, 1.1,  # –ë—ã—á–∏–π —Ä—ã–Ω–æ–∫
                                  np.where(asymmetry_ratio < 0.9, 0.9,   # –ú–µ–¥–≤–µ–∂–∏–π —Ä—ã–Ω–æ–∫
                                  1.0))  # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä—ã–Ω–æ–∫
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—ä–µ–º–∞
            volume_adjustment = np.where(volume_ratio > 1.5, 0.9,  # –í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º - —Å–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥–∏
                               np.where(volume_ratio < 0.7, 1.2,   # –ù–∏–∑–∫–∏–π –æ–±—ä–µ–º - –ø–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥–∏
                               1.0))  # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            vol_of_vol_adjustment = np.where(vol_of_vol_normalized > 0.5, 0.8,  # –í—ã—Å–æ–∫–∞—è –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å
                                   np.where(vol_of_vol_normalized < 0.2, 1.2,   # –ù–∏–∑–∫–∞—è –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å
                                   1.0))  # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏
            fall_multiplier = fall_multiplier * vol_adjustment * trend_adjustment * asymmetry_adjustment * volume_adjustment * vol_of_vol_adjustment
            rise_multiplier = rise_multiplier * vol_adjustment * trend_adjustment * asymmetry_adjustment * volume_adjustment * vol_of_vol_adjustment
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª–∏ —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
            fall_multiplier = fall_multiplier.clip(0.5, 3.0)
            rise_multiplier = rise_multiplier.clip(0.5, 3.0)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–Ω–æ–∂–∏—Ç–µ–ª–µ–π
            avg_fall_mult = fall_multiplier.mean()
            avg_rise_mult = rise_multiplier.mean()
            
            self.logger.info(f"–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏:")
            self.logger.info(f"  –ü–∞–¥–µ–Ω–∏–µ: {avg_fall_mult:.2f} (–¥–∏–∞–ø–∞–∑–æ–Ω: {fall_multiplier.min():.2f}-{fall_multiplier.max():.2f})")
            self.logger.info(f"  –†–æ—Å—Ç: {avg_rise_mult:.2f} (–¥–∏–∞–ø–∞–∑–æ–Ω: {rise_multiplier.min():.2f}-{rise_multiplier.max():.2f})")
            
            return {
                'fall': fall_multiplier,
                'rise': rise_multiplier
            }
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –º–Ω–æ–∂–∏—Ç–µ–ª–µ–π: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return {
                'fall': pd.Series(1.5, index=data.index),
                'rise': pd.Series(1.5, index=data.index)
            }
    
    def _add_horizon_based_features(self, df: pd.DataFrame, horizon: int) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            horizon: –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            
        Returns:
            DataFrame —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        try:
            # –ù–û–í–û–ï: –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            df[f'trend_{horizon}'] = df['close'].rolling(horizon).apply(
                lambda x: 1 if x.iloc[-1] > x.iloc[0] else (-1 if x.iloc[-1] < x.iloc[0] else 0)
            )
            
            # –ù–û–í–û–ï: –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ
            df[f'volatility_{horizon}'] = df['close'].pct_change().rolling(horizon).std()
            
            # –ù–û–í–û–ï: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ
            df[f'max_price_{horizon}'] = df['close'].rolling(horizon).max()
            df[f'min_price_{horizon}'] = df['close'].rolling(horizon).min()
            
            # –ù–û–í–û–ï: –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –º–∞–∫—Å–∏–º—É–º–∞ –∏ –º–∏–Ω–∏–º—É–º–∞
            df[f'distance_to_max_{horizon}'] = (df[f'max_price_{horizon}'] - df['close']) / df['close']
            df[f'distance_to_min_{horizon}'] = (df['close'] - df[f'min_price_{horizon}']) / df['close']
            
            # –ù–û–í–û–ï: –ú–æ–º–µ–Ω—Ç—É–º –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ
            df[f'momentum_{horizon}'] = df['close'] / df['close'].shift(horizon) - 1
            
            # –ù–û–í–û–ï: –û–±—ä–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ
            df[f'volume_profile_{horizon}'] = df['volume'].rolling(horizon).mean()
            df[f'volume_ratio_{horizon}'] = df['volume'] / df[f'volume_profile_{horizon}']
            
            self.logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ {horizon}")
            return df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞: {e}")
            return df
    
    def process_multi_timeframe(self, data_dict: Dict[str, pd.DataFrame], symbol: str) -> Optional[pd.DataFrame]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤.
        
        Args:
            data_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        
        Returns:
            DataFrame —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            self.logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è {symbol}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            if not self.multi_tf_processor.validate_timeframe_data(data_dict):
                self.logger.error(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞ –¥–ª—è {symbol}")
                return None
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
            processed_data = {}
            
            for timeframe, df in data_dict.items():
                self.logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º {timeframe}")
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
                processed_df = df.copy()
                processed_df = self.process_single_timeframe(processed_df, symbol, timeframe)
                
                if processed_df is not None:
                    processed_data[timeframe] = processed_df
                    self.logger.info(f"–¢–∞–π–º—Ñ—Ä–µ–π–º {timeframe}: {len(processed_df)} —Å—Ç—Ä–æ–∫, {len(processed_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                else:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {timeframe}")
            
            if not processed_data:
                self.logger.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤")
                return None
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            combined_df = self.multi_tf_processor.process_multi_timeframe_data(processed_data, symbol)
            
            if combined_df is None or combined_df.empty:
                self.logger.error("–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤")
                return None
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            initial_rows = len(combined_df)
            combined_df = combined_df.dropna()
            final_rows = len(combined_df)
            
            if final_rows < initial_rows:
                self.logger.warning(f"–£–¥–∞–ª–µ–Ω–æ {initial_rows - final_rows} —Å—Ç—Ä–æ–∫ —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            if len(combined_df) < 100:
                self.logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(combined_df)} —Å—Ç—Ä–æ–∫")
                return None
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.processing_stats['total_features'] = len(combined_df.columns)
            self.processing_stats['timeframes_processed'] = len(processed_data)
            self.processing_stats['balance_ratio_before'] = self._calculate_balance_ratio(combined_df)
            
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(combined_df)} —Å—Ç—Ä–æ–∫, {len(combined_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            self.logger.info(f"–ö–æ–ª–æ–Ω–∫–∏ –≤ –∏—Ç–æ–≥–æ–≤–æ–º DataFrame: {list(combined_df.columns)}")
            
            return combined_df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è {symbol}: {e}")
            return None
    
    def balance_data(self, df: pd.DataFrame, symbol: str) -> Optional[pd.DataFrame]:
        """
        –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        
        Returns:
            –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            if df is None or df.empty:
                self.logger.error(f"–ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ {symbol}")
                return None
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            if 'target' not in df.columns:
                self.logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è {symbol}")
                return None
            
            self.logger.info(f"–ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            X = df.drop('target', axis=1)
            y = df['target']
            
            # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X_balanced, y_balanced = self.balancer.balance_data(X, y, method='auto')
            
            if X_balanced is None or y_balanced is None:
                self.logger.error(f"–û—à–∏–±–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
                return None
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ DataFrame
            balanced_df = X_balanced.copy()
            balanced_df['target'] = y_balanced
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.processing_stats['balance_ratio_after'] = self._calculate_balance_ratio(balanced_df)
            
            self.logger.info(f"–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(balanced_df)} —Å—Ç—Ä–æ–∫")
            self.logger.info(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –¥–æ: {self.processing_stats['balance_ratio_before']:.3f}")
            self.logger.info(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ—Å–ª–µ: {self.processing_stats['balance_ratio_after']:.3f}")
            
            return balanced_df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            return None
    
    def prepare_for_training(self, df: pd.DataFrame, symbol: str) -> Tuple[Optional[pd.DataFrame], Optional[pd.Series]]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        
        Args:
            df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        
        Returns:
            Tuple —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ (None, None) –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            if df is None or df.empty:
                self.logger.error(f"–ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –æ–±—É—á–µ–Ω–∏—é {symbol}")
                return None, None
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            if 'target' not in df.columns:
                self.logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è {symbol}")
                return None, None
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            X = df.drop('target', axis=1)
            y = df['target']
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            constant_columns = [col for col in X.columns if X[col].nunique() <= 1]
            if constant_columns:
                self.logger.warning(f"–£–¥–∞–ª–µ–Ω—ã –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {constant_columns}")
                X = X.drop(constant_columns, axis=1)
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º NaN –∑–Ω–∞—á–µ–Ω–∏–π
            nan_threshold = 0.5
            nan_columns = [col for col in X.columns if X[col].isnull().sum() / len(X) > nan_threshold]
            if nan_columns:
                self.logger.warning(f"–£–¥–∞–ª–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º NaN: {nan_columns}")
                X = X.drop(nan_columns, axis=1)
            
            # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è NaN –∑–Ω–∞—á–µ–Ω–∏–π
            X = X.fillna(method='ffill').fillna(method='bfill').fillna(0)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if len(X.columns) < 5:
                self.logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(X.columns)}")
                return None, None
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.processing_stats['target_distribution'] = y.value_counts().to_dict()
            
            self.logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(X)} —Å—Ç—Ä–æ–∫, {len(X.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            self.logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: {dict(y.value_counts())}")
            
            return X, y
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è {symbol}: {e}")
            return None, None
    
    def get_feature_importance(self, model, feature_names: List[str]) -> Dict[str, float]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Ç –º–æ–¥–µ–ª–∏.
        
        Args:
            model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å feature_importances_
            feature_names: –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        try:
            if hasattr(model, 'feature_importances_'):
                importance_dict = dict(zip(feature_names, model.feature_importances_))
                
                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                sorted_importance = dict(sorted(importance_dict.items(), 
                                               key=lambda x: x[1], reverse=True))
                
                self.processing_stats['feature_importance'] = sorted_importance
                
                self.logger.info("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–ª—É—á–µ–Ω–∞")
                return sorted_importance
            else:
                self.logger.warning("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç feature_importances_")
                return {}
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return {}
    
    def _calculate_balance_ratio(self, df: pd.DataFrame) -> float:
        """
        –†–∞—Å—á–µ—Ç —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤.
        
        Args:
            df: DataFrame —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        
        Returns:
            –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
        """
        try:
            # –ò—â–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–º–æ–∂–µ—Ç –±—ã—Ç—å target, target_dynamic, target_3class)
            target_columns = ['target', 'target_dynamic', 'target_3class']
            target_col = None
            
            for col in target_columns:
                if col in df.columns:
                    target_col = col
                    break
            
            if target_col is None:
                return 0.0
            
            target_counts = df[target_col].value_counts()
            if len(target_counts) < 2:
                return 0.0
            
            min_count = target_counts.min()
            max_count = target_counts.max()
            
            return min_count / max_count if max_count > 0 else 0.0
            
        except Exception:
            return 0.0
    
    def get_processing_statistics(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        stats = self.processing_stats.copy()
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        stats['indicators_enabled'] = len(self.indicators_config) > 0
        stats['balancing_enabled'] = self.balancing_config.get('enabled', False)
        stats['multi_timeframe_enabled'] = self.multi_tf_config.get('enabled', False)
        
        return stats
    
    def reset_statistics(self):
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        self.processing_stats = {
            'total_features': 0,
            'timeframes_processed': 0,
            'balance_ratio_before': 0,
            'balance_ratio_after': 0,
            'target_distribution': {},
            'feature_importance': {},
            'processing_time': 0
        }
        self.logger.info("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–±—Ä–æ—à–µ–Ω–∞")

    def add_rolling_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏
        """
        try:
            self.logger.info("–î–æ–±–∞–≤–ª–µ–Ω–∏–µ rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫")
            
            # Rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ü–µ–Ω—ã
            price_columns = ['close', 'high', 'low', 'open']
            for col in price_columns:
                if col in df.columns:
                    # Rolling mean —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏
                    df[f'rolling_mean_5_{col}'] = df[col].rolling(window=5).mean()
                    df[f'rolling_mean_10_{col}'] = df[col].rolling(window=10).mean()
                    df[f'rolling_mean_20_{col}'] = df[col].rolling(window=20).mean()
                    
                    # Rolling max/min
                    df[f'rolling_max_50_{col}'] = df[col].rolling(window=50).max()
                    df[f'rolling_min_50_{col}'] = df[col].rolling(window=50).min()
                    
                    # Rolling std
                    df[f'rolling_std_20_{col}'] = df[col].rolling(window=20).std()
                    
                    # Rolling quantiles
                    df[f'rolling_q75_20_{col}'] = df[col].rolling(window=20).quantile(0.75)
                    df[f'rolling_q25_20_{col}'] = df[col].rolling(window=20).quantile(0.25)
            
            # Rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ–±—ä–µ–º–∞
            if 'volume' in df.columns:
                df['rolling_mean_5_volume'] = df['volume'].rolling(window=5).mean()
                df['rolling_max_50_volume'] = df['volume'].rolling(window=50).max()
                df['rolling_std_20_volume'] = df['volume'].rolling(window=20).std()
                df['volume_ratio_5'] = df['volume'] / df['rolling_mean_5_volume']
                df['volume_ratio_50'] = df['volume'] / df['rolling_max_50_volume']
            
            # Rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            indicator_columns = [col for col in df.columns if any(indicator in col.lower() 
                                                               for indicator in ['rsi', 'macd', 'sma', 'ema', 'bb'])]
            
            for col in indicator_columns:
                if col in df.columns:
                    df[f'rolling_mean_5_{col}'] = df[col].rolling(window=5).mean()
                    df[f'rolling_std_20_{col}'] = df[col].rolling(window=20).std()
                    df[f'rolling_max_50_{col}'] = df[col].rolling(window=50).max()
                    df[f'rolling_min_50_{col}'] = df[col].rolling(window=50).min()
            
            # –¶–µ–Ω–æ–≤—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏
            if 'close' in df.columns:
                df['price_vs_rolling_mean_5'] = df['close'] / df['rolling_mean_5_close']
                df['price_vs_rolling_mean_20'] = df['close'] / df['rolling_mean_20_close']
                df['price_vs_rolling_max_50'] = df['close'] / df['rolling_max_50_close']
                df['price_vs_rolling_min_50'] = df['close'] / df['rolling_min_50_close']
            
            self.logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len([col for col in df.columns if 'rolling_' in col])} rolling –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫: {e}")
            return df

    def select_top_features(self, df: pd.DataFrame, target_col: str = 'target', 
                           n_features: int = 30, importance_threshold: float = 0.005) -> pd.DataFrame:
        """
        –û—Ç–±–∏—Ä–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–æ–ø-N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞.
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            target_col: –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            n_features: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞
            importance_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞
            
        Returns:
            DataFrame —Ç–æ–ª—å–∫–æ —Å –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        try:
            self.logger.info(f"–û—Ç–±–æ—Ä —Ç–æ–ø-{n_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ—Ä–æ–≥–æ–º –≤–∞–∂–Ω–æ—Å—Ç–∏ {importance_threshold}")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X = df.drop([target_col], axis=1, errors='ignore')
            y = df[target_col]
            
            # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å NaN
            X = X.dropna(axis=1)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º mutual information –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
            from sklearn.feature_selection import mutual_info_classif
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            importance_scores = mutual_info_classif(X, y, random_state=42)
            feature_importance = dict(zip(X.columns, importance_scores))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É –≤–∞–∂–Ω–æ—Å—Ç–∏
            filtered_features = [(name, score) for name, score in sorted_features if score >= importance_threshold]
            
            # –ë–µ—Ä–µ–º —Ç–æ–ø-N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            top_features = filtered_features[:n_features]
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(filtered_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é >= {importance_threshold}")
            self.logger.info(f"–û—Ç–æ–±—Ä–∞–Ω–æ —Ç–æ–ø-{len(top_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
            
            for i, (feature, importance) in enumerate(top_features, 1):
                self.logger.info(f"{i:2d}. {feature}: {importance:.6f}")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame —Ç–æ–ª—å–∫–æ —Å –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            selected_columns = [target_col] + [feature for feature, _ in top_features]
            selected_df = df[selected_columns].copy()
            
            self.logger.info(f"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {selected_df.shape}")
            return selected_df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return df 

    def process_features(self, data: pd.DataFrame, symbol: str, timeframe: str,
                         prediction_horizon: int = None, adaptive_indicators_enabled: bool = True,
                         fixed_indicators: List[str] = None) -> pd.DataFrame:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≥–∏–±–∫–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã—Ö
            prediction_horizon: –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
            adaptive_indicators_enabled: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            fixed_indicators: –°–ø–∏—Å–æ–∫ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        
        Returns:
            DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        try:
            self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol} –Ω–∞ {timeframe}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            if prediction_horizon is None:
                prediction_horizon = self.prediction_horizons.get(timeframe, 12)
            self.logger.info(f"–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {prediction_horizon} —Å–≤–µ—á–µ–π")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
            processed_df = data.copy()
            
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ø–æ—Å–æ–± —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if adaptive_indicators_enabled and self.config.get('adaptive_indicators', {}).get('enabled', True):
                self.logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
                
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏
                optimization_results = self.adaptive_selector.optimize_indicators(
                    processed_df, timeframe, force_recalculate=not self._use_cached_indicators
                )
                
                if optimization_results and 'best_combination' in optimization_results:
                    self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –ª—É—á—à–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {optimization_results['best_combination']}")
                    processed_df = self.adaptive_selector.add_best_indicators(processed_df, timeframe)
                else:
                    self.logger.warning("‚ö†Ô∏è –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
                    processed_df = self.indicators.add_all_indicators(processed_df)
                    
            elif fixed_indicators:
                self.logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {fixed_indicators}")
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                for indicator in fixed_indicators:
                    if indicator == 'rsi':
                        processed_df = self.indicators.add_rsi(processed_df)
                    elif indicator == 'macd':
                        processed_df = self.indicators.add_macd(processed_df)
                    elif indicator == 'obv':
                        processed_df = self.indicators.add_obv(processed_df)
                    elif indicator == 'vwap':
                        processed_df = self.indicators.add_vwap(processed_df)
                    elif indicator == 'atr':
                        processed_df = self.indicators.add_atr(processed_df)
                    elif indicator == 'williams_r':
                        processed_df = self.indicators.add_williams_r(processed_df)
                    elif indicator == 'cci':
                        processed_df = self.indicators.add_cci(processed_df)
                    elif indicator == 'mfi':
                        processed_df = self.indicators.add_advanced_volume_indicators(processed_df)
                    elif indicator == 'sma':
                        processed_df = self.indicators.add_sma(processed_df, 20)
                        processed_df = self.indicators.add_sma(processed_df, 50)
                    elif indicator == 'ema':
                        processed_df = self.indicators.add_ema(processed_df, 12)
                        processed_df = self.indicators.add_ema(processed_df, 26)
                    elif indicator == 'bollinger_bands':
                        processed_df = self.indicators.add_bollinger_bands(processed_df)
                    else:
                        self.logger.warning(f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä {indicator} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                        
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                self.logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
                processed_df = self.indicators.add_all_indicators(processed_df)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º
            processed_df = self._create_target_with_horizon(processed_df, prediction_horizon)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            processed_df = self._add_horizon_based_features(processed_df, prediction_horizon)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            initial_rows = len(processed_df)
            processed_df = processed_df.dropna()
            removed_rows = initial_rows - len(processed_df)
            
            if removed_rows > 0:
                self.logger.warning(f"–£–¥–∞–ª–µ–Ω–æ {removed_rows} —Å—Ç—Ä–æ–∫ —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            if len(processed_df) < 100:
                self.logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(processed_df)} —Å—Ç—Ä–æ–∫")
                return processed_df
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.processing_stats['total_features'] = len(processed_df.columns)
            self.processing_stats['balance_ratio_before'] = self._calculate_balance_ratio(processed_df)
            
            self.logger.info(f"–ò–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {processed_df.shape}")
            
            return processed_df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}: {e}")
            return data 

    def _add_simplified_sentiment_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ sentiment —Ñ–∏—á–∏ (—Ç–æ–ª—å–∫–æ Bybit Opportunities).
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        
        Returns:
            DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ sentiment —Ñ–∏—á–∞–º–∏
        """
        try:
            self.logger.info("–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö sentiment —Ñ–∏—á–µ–π (Bybit Opportunities)")
            
            # –ü–æ–ª—É—á–∞–µ–º Bybit market opportunities
            bybit_data = self.sentiment_collector.get_bybit_opportunities()
            
            if bybit_data:
                # –ë–∞–∑–æ–≤—ã–µ sentiment —Ñ–∏—á–∏
                df['bybit_market_sentiment'] = bybit_data.get('market_sentiment', 0.5)
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ—Ä—è—á–∏—Ö —Å–µ–∫—Ç–æ—Ä–æ–≤
                hot_sectors = bybit_data.get('hot_sectors', [])
                df['bybit_hot_sectors_count'] = len(hot_sectors)
                
                # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∏–Ω–≥–æ–≤—ã—Ö –º–æ–Ω–µ—Ç
                trending_coins = bybit_data.get('trending_coins', [])
                if trending_coins:
                    positive_trending = sum(1 for coin in trending_coins if coin.get('sentiment', 0) > 0)
                    df['bybit_positive_trending_ratio'] = positive_trending / len(trending_coins)
                else:
                    df['bybit_positive_trending_ratio'] = 0.5
                
                # Gainers vs Losers ratio
                gainers_losers = bybit_data.get('gainers_losers', {})
                gainers_count = len(gainers_losers.get('gainers', []))
                losers_count = len(gainers_losers.get('losers', []))
                
                if gainers_count + losers_count > 0:
                    df['bybit_gainers_ratio'] = gainers_count / (gainers_count + losers_count)
                else:
                    df['bybit_gainers_ratio'] = 0.5
                
                # Composite sentiment score (simplified)
                df['sentiment_composite_score'] = (
                    df['bybit_market_sentiment'] * 0.4 +
                    df['bybit_positive_trending_ratio'] * 0.3 +
                    df['bybit_gainers_ratio'] * 0.3
                )
                
                # Market regime classification (simplified)
                df['market_regime_bullish'] = (df['sentiment_composite_score'] > 0.6).astype(int)
                df['market_regime_bearish'] = (df['sentiment_composite_score'] < 0.4).astype(int)
                df['market_regime_neutral'] = (
                    (df['sentiment_composite_score'] >= 0.4) & 
                    (df['sentiment_composite_score'] <= 0.6)
                ).astype(int)
                
                self.logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã simplified sentiment —Ñ–∏—á–∏:")
                self.logger.info(f"  ‚Ä¢ Market Sentiment: {df['bybit_market_sentiment'].iloc[-1]:.3f}")
                self.logger.info(f"  ‚Ä¢ Hot Sectors: {df['bybit_hot_sectors_count'].iloc[-1]}")
                self.logger.info(f"  ‚Ä¢ Positive Trending Ratio: {df['bybit_positive_trending_ratio'].iloc[-1]:.3f}")
                self.logger.info(f"  ‚Ä¢ Gainers Ratio: {df['bybit_gainers_ratio'].iloc[-1]:.3f}")
                self.logger.info(f"  ‚Ä¢ Composite Score: {df['sentiment_composite_score'].iloc[-1]:.3f}")
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
                if df['market_regime_bullish'].iloc[-1]:
                    regime = "üêÇ –ë–´–ß–ò–ô"
                elif df['market_regime_bearish'].iloc[-1]:
                    regime = "üêª –ú–ï–î–í–ï–ñ–ò–ô"
                else:
                    regime = "üòê –ù–ï–ô–¢–†–ê–õ–¨–ù–´–ô"
                
                self.logger.info(f"  ‚Ä¢ Market Regime: {regime}")
                
            else:
                self.logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å Bybit –¥–∞–Ω–Ω—ã–µ, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
                df['bybit_market_sentiment'] = 0.5
                df['bybit_hot_sectors_count'] = 3
                df['bybit_positive_trending_ratio'] = 0.5
                df['bybit_gainers_ratio'] = 0.5
                df['sentiment_composite_score'] = 0.5
                df['market_regime_bullish'] = 0
                df['market_regime_bearish'] = 0
                df['market_regime_neutral'] = 1
            
            return df
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è sentiment —Ñ–∏—á–µ–π: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            df['bybit_market_sentiment'] = 0.5
            df['bybit_hot_sectors_count'] = 3
            df['bybit_positive_trending_ratio'] = 0.5
            df['bybit_gainers_ratio'] = 0.5
            df['sentiment_composite_score'] = 0.5
            df['market_regime_bullish'] = 0
            df['market_regime_bearish'] = 0
            df['market_regime_neutral'] = 1
            return df