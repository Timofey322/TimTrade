"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞
"""

import os
import time
import psutil
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from typing import List, Dict, Any, Callable, Optional, Tuple
import numpy as np
import pandas as pd
from loguru import logger
import multiprocessing as mp


class ParallelProcessor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
    """
    
    def __init__(self, config: Dict = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        self.config = config or {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏
        self.max_workers = self.config.get('max_workers', -1)
        if self.max_workers == -1:
            self.max_workers = psutil.cpu_count()
        
        self.chunk_size = self.config.get('chunk_size', 1000)
        self.use_threadpool = self.config.get('use_threadpool', True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        self.cache_enabled = self.config.get('cache_enabled', True)
        self.memory_cache = {}
        
        logger.info(f"üöÄ ParallelProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.max_workers} —è–¥–µ—Ä")
    
    def parallel_map(self, func: Callable, data: List, 
                    use_processes: bool = False, 
                    chunk_size: Optional[int] = None) -> List:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫ –¥–∞–Ω–Ω—ã–º
        
        Args:
            func: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            use_processes: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –≤–º–µ—Å—Ç–æ –ø–æ—Ç–æ–∫–æ–≤
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (None –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ)
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        if not data:
            return []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
        if chunk_size is None:
            chunk_size = max(1, len(data) // (self.max_workers * 4))
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —á–∞–Ω–∫–∏
        chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
        
        logger.info(f"üîß –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {len(chunks)} —á–∞–Ω–∫–æ–≤ –ø–æ {chunk_size} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        
        # –í—ã–±–∏—Ä–∞–µ–º executor
        if use_processes:
            executor_class = ProcessPoolExecutor
        else:
            executor_class = ThreadPoolExecutor
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        with executor_class(max_workers=self.max_workers) as executor:
            futures = [executor.submit(func, chunk) for chunk in chunks]
            
            results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                    results.append(None)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if isinstance(results[0], (list, tuple)):
            return [item for sublist in results if sublist is not None for item in sublist]
        else:
            return results
    
    def parallel_dataframe_processing(self, df: pd.DataFrame, 
                                    func: Callable,
                                    column_chunks: bool = False,
                                    use_processes: bool = False) -> pd.DataFrame:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DataFrame
        
        Args:
            df: DataFrame –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            func: –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            column_chunks: –†–∞–∑–±–∏–≤–∞—Ç—å –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º –≤–º–µ—Å—Ç–æ —Å—Ç—Ä–æ–∫
            use_processes: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã
        
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
        """
        if df.empty:
            return df
        
        if column_chunks:
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
            columns = list(df.columns)
            chunk_size = max(1, len(columns) // self.max_workers)
            column_chunks = [columns[i:i+chunk_size] for i in range(0, len(columns), chunk_size)]
            
            logger.info(f"üîß –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω–æ–∫: {len(column_chunks)} —á–∞–Ω–∫–æ–≤")
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = {
                    executor.submit(func, df[cols]): cols 
                    for cols in column_chunks
                }
                
                results = {}
                for future in as_completed(futures):
                    cols = futures[future]
                    try:
                        result = future.result()
                        results.update({col: result[col] for col in cols})
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–ª–æ–Ω–æ–∫ {cols}: {e}")
                
                return pd.DataFrame(results)
        
        else:
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
            chunk_size = max(1, len(df) // (self.max_workers * 4))
            row_chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]
            
            logger.info(f"üîß –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫: {len(row_chunks)} —á–∞–Ω–∫–æ–≤")
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = [executor.submit(func, chunk) for chunk in row_chunks]
                
                results = []
                for future in as_completed(futures):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞: {e}")
                        results.append(pd.DataFrame())
                
                return pd.concat(results, ignore_index=True)
    
    def parallel_feature_engineering(self, df: pd.DataFrame, 
                                   feature_functions: List[Callable],
                                   use_processes: bool = False) -> pd.DataFrame:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            df: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
            feature_functions: –°–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            use_processes: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã
        
        Returns:
            DataFrame —Å –Ω–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        if not feature_functions:
            return df
        
        logger.info(f"üîß –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ {len(feature_functions)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞ —á–∞–Ω–∫–∏
        chunk_size = max(1, len(feature_functions) // self.max_workers)
        function_chunks = [feature_functions[i:i+chunk_size] 
                          for i in range(0, len(feature_functions), chunk_size)]
        
        def process_feature_chunk(funcs):
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ —Ñ—É–Ω–∫—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
            result_df = df.copy()
            for func in funcs:
                try:
                    result_df = func(result_df)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞: {e}")
            return result_df
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(process_feature_chunk, funcs) 
                      for funcs in function_chunks]
            
            results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
                    results.append(df)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π, —Ç–∞–∫ –∫–∞–∫ –∫–∞–∂–¥–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç DataFrame)
        if results:
            return results[-1]
        else:
            return df
    
    def parallel_model_training(self, models: List, 
                              train_data: Tuple,
                              use_processes: bool = False) -> List:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        
        Args:
            models: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            train_data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (X, y)
            use_processes: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã
        
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        if not models:
            return []
        
        logger.info(f"üß† –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ {len(models)} –º–æ–¥–µ–ª–µ–π")
        
        def train_single_model(model):
            """–û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
            try:
                if hasattr(model, 'fit'):
                    model.fit(*train_data)
                elif hasattr(model, 'train'):
                    model.train(*train_data)
                return model
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
                return None
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(models))) as executor:
            futures = [executor.submit(train_single_model, model) for model in models]
            
            trained_models = []
            for future in as_completed(futures):
                try:
                    model = future.result()
                    if model is not None:
                        trained_models.append(model)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–æ {len(trained_models)}/{len(models)} –º–æ–¥–µ–ª–µ–π")
        return trained_models
    
    def parallel_hyperparameter_optimization(self, 
                                           model_class,
                                           param_spaces: List[Dict],
                                           train_data: Tuple,
                                           eval_func: Callable,
                                           use_processes: bool = False) -> List[Dict]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Args:
            model_class: –ö–ª–∞—Å—Å –º–æ–¥–µ–ª–∏
            param_spaces: –°–ø–∏—Å–æ–∫ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            train_data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            eval_func: –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
            use_processes: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        """
        if not param_spaces:
            return []
        
        logger.info(f"‚öôÔ∏è –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {len(param_spaces)} –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        def optimize_single_space(param_space):
            """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
            try:
                # –ü—Ä–æ—Å—Ç–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é)
                best_score = -np.inf
                best_params = None
                
                for _ in range(10):  # 10 –ø–æ–ø—ã—Ç–æ–∫
                    # –°–ª—É—á–∞–π–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    params = {}
                    for key, value_range in param_space.items():
                        if isinstance(value_range, (list, tuple)):
                            params[key] = np.random.choice(value_range)
                        else:
                            params[key] = value_range
                    
                    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                    model = model_class(**params)
                    model.fit(*train_data)
                    
                    # –û—Ü–µ–Ω–∏–≤–∞–µ–º
                    score = eval_func(model, *train_data)
                    
                    if score > best_score:
                        best_score = score
                        best_params = params
                
                return {'params': best_params, 'score': best_score}
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞: {e}")
                return None
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(param_spaces))) as executor:
            futures = [executor.submit(optimize_single_space, space) for space in param_spaces]
            
            results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result is not None:
                        results.append(result)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
        
        logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(results)}/{len(param_spaces)} –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤")
        return results
    
    def parallel_backtesting(self, 
                           models: List,
                           data: pd.DataFrame,
                           backtest_configs: List[Dict],
                           use_processes: bool = False) -> List[Dict]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥
        
        Args:
            models: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
            backtest_configs: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
            use_processes: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        """
        if not models or not backtest_configs:
            return []
        
        logger.info(f"üìà –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ {len(models)} –º–æ–¥–µ–ª–µ–π —Å {len(backtest_configs)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏")
        
        def run_single_backtest(model, config):
            """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∞"""
            try:
                # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é)
                predictions = model.predict(data)
                
                # –ü—Ä–æ—Å—Ç–∞—è —Å–∏–º—É–ª—è—Ü–∏—è —Ç–æ—Ä–≥–æ–≤–ª–∏
                returns = []
                position = 0
                
                for i, pred in enumerate(predictions):
                    if pred > 0.6 and position == 0:  # –ü–æ–∫—É–ø–∫–∞
                        position = 1
                    elif pred < 0.4 and position == 1:  # –ü—Ä–æ–¥–∞–∂–∞
                        position = 0
                        returns.append(0.1)  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
                
                total_return = sum(returns) if returns else 0
                
                return {
                    'model_id': id(model),
                    'config': config,
                    'total_return': total_return,
                    'num_trades': len(returns),
                    'sharpe_ratio': np.mean(returns) / np.std(returns) if len(returns) > 1 else 0
                }
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫—Ç–µ—Å—Ç–∞: {e}")
                return None
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        tasks = []
        for model in models:
            for config in backtest_configs:
                tasks.append((model, config))
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥
        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(tasks))) as executor:
            futures = [executor.submit(run_single_backtest, model, config) 
                      for model, config in tasks]
            
            results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result is not None:
                        results.append(result)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –±—ç–∫—Ç–µ—Å—Ç–∞: {e}")
        
        logger.info(f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ {len(results)}/{len(tasks)} –±—ç–∫—Ç–µ—Å—Ç–æ–≤")
        return results
    
    def get_performance_stats(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            stats = {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'memory_used_gb': memory.used / (1024**3),
                'memory_available_gb': memory.available / (1024**3),
                'max_workers': self.max_workers,
                'active_threads': threading.active_count()
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}


class MemoryCache:
    """
    –ö—ç—à –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    
    def __init__(self, max_size_mb: int = 1024):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞
        
        Args:
            max_size_mb: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ –≤ –ú–ë
        """
        self.max_size_bytes = max_size_mb * 1024 * 1024
        self.cache = {}
        self.access_times = {}
        self.lock = threading.Lock()
    
    def get(self, key: str) -> Any:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞
        
        Args:
            key: –ö–ª—é—á
        
        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ None
        """
        with self.lock:
            if key in self.cache:
                self.access_times[key] = time.time()
                return self.cache[key]
            return None
    
    def set(self, key: str, value: Any):
        """
        –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫—ç—à
        
        Args:
            key: –ö–ª—é—á
            value: –ó–Ω–∞—á–µ–Ω–∏–µ
        """
        with self.lock:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            current_size = sum(self._get_size(v) for v in self.cache.values())
            value_size = self._get_size(value)
            
            # –ï—Å–ª–∏ –∫—ç—à –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω, —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
            while current_size + value_size > self.max_size_bytes and self.cache:
                oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
                current_size -= self._get_size(self.cache[oldest_key])
                del self.cache[oldest_key]
                del self.access_times[oldest_key]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            self.cache[key] = value
            self.access_times[key] = time.time()
    
    def _get_size(self, obj: Any) -> int:
        """
        –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –æ–±—ä–µ–∫—Ç–∞ –≤ –±–∞–π—Ç–∞—Ö
        
        Args:
            obj: –û–±—ä–µ–∫—Ç
        
        Returns:
            –†–∞–∑–º–µ—Ä –≤ –±–∞–π—Ç–∞—Ö
        """
        try:
            if isinstance(obj, pd.DataFrame):
                return obj.memory_usage(deep=True).sum()
            elif isinstance(obj, np.ndarray):
                return obj.nbytes
            elif isinstance(obj, (list, tuple)):
                return sum(self._get_size(item) for item in obj)
            elif isinstance(obj, dict):
                return sum(self._get_size(v) for v in obj.values())
            else:
                return len(str(obj).encode('utf-8'))
        except:
            return 1024  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def clear(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞"""
        with self.lock:
            self.cache.clear()
            self.access_times.clear()
    
    def get_stats(self) -> Dict:
        """
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        with self.lock:
            total_size = sum(self._get_size(v) for v in self.cache.values())
            return {
                'entries': len(self.cache),
                'size_mb': total_size / (1024 * 1024),
                'max_size_mb': self.max_size_bytes / (1024 * 1024),
                'usage_percent': (total_size / self.max_size_bytes) * 100
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–µ–∫—Ç–µ
parallel_processor = ParallelProcessor()
memory_cache = MemoryCache() 