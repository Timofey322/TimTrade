#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é –º–æ–¥–µ–ª–∏.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –Ω–∏–∑–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ (55%).
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import yaml
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from loguru import logger
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_class_weight
from src.data_collection.collector import DataCollector
from src.preprocessing.feature_engineering import FeatureEngineer
from src.ml_models.advanced_xgboost_model import AdvancedEnsembleModel

def diagnose_accuracy_issues():
    """–ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é –º–æ–¥–µ–ª–∏."""
    
    logger.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú –° –¢–û–ß–ù–û–°–¢–¨–Æ –ú–û–î–ï–õ–ò")
    logger.info("=" * 60)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        with open('config/smart_adaptive_config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # 1. –°–ë–û–† –î–ê–ù–ù–´–•
        logger.info("\nüìä 1. –°–ë–û–† –î–ê–ù–ù–´–•")
        logger.info("-" * 30)
        
        collector = DataCollector(config['data_collection'])
        data_5m = collector.fetch_ohlcv('BTC/USDT', '5m', limit=20000)
        data_15m = collector.fetch_ohlcv('BTC/USDT', '15m', limit=20000)
        
        if data_5m is None or data_15m is None:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return False
        
        logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö: 5m={len(data_5m)}, 15m={len(data_15m)}")
        
        # 2. –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•
        logger.info("\nüîß 2. –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•")
        logger.info("-" * 30)
        
        feature_engineer = FeatureEngineer(config['preprocessing'])
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        processed_data = feature_engineer.process_multi_timeframe(
            {'5m': data_5m, '15m': data_15m}, 
            'BTC/USDT'
        )
        
        if processed_data is None:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            return False
        
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(processed_data)} —Å—Ç—Ä–æ–∫")
        logger.info(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(processed_data.columns)}")
        
        # 3. –ê–ù–ê–õ–ò–ó –¶–ï–õ–ï–í–û–ô –ü–ï–†–ï–ú–ï–ù–ù–û–ô
        logger.info("\nüéØ 3. –ê–ù–ê–õ–ò–ó –¶–ï–õ–ï–í–û–ô –ü–ï–†–ï–ú–ï–ù–ù–û–ô")
        logger.info("-" * 30)
        
        if 'target' not in processed_data.columns:
            logger.error("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è")
            return False
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –î–û –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        target_dist_before = processed_data['target'].value_counts()
        logger.info(f"üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –î–û –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:")
        for class_id, count in target_dist_before.items():
            percentage = count / len(processed_data) * 100
            logger.info(f"  –ö–ª–∞—Å—Å {class_id}: {count} ({percentage:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
        min_class = target_dist_before.min()
        max_class = target_dist_before.max()
        balance_ratio = min_class / max_class
        logger.info(f"üìä –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {balance_ratio:.3f}")
        
        if balance_ratio < 0.3:
            logger.warning("‚ö†Ô∏è –°–ò–õ–¨–ù–´–ô –î–ò–°–ë–ê–õ–ê–ù–° –ö–õ–ê–°–°–û–í! –ù—É–∂–Ω–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞.")
        elif balance_ratio < 0.7:
            logger.warning("‚ö†Ô∏è –£–ú–ï–†–ï–ù–ù–´–ô –î–ò–°–ë–ê–õ–ê–ù–° –ö–õ–ê–°–°–û–í.")
        else:
            logger.info("‚úÖ –ö–ª–∞—Å—Å—ã –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã.")
        
        # 4. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–ù–´–• –ì–û–†–ò–ó–û–ù–¢–û–í –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø
        logger.info("\n‚è∞ 4. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–ù–´–• –ì–û–†–ò–ó–û–ù–¢–û–í –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø")
        logger.info("-" * 30)
        
        horizons = [3, 6, 12, 24]
        horizon_results = {}
        
        for horizon in horizons:
            logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç: {horizon} —Å–≤–µ—á–µ–π")
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            temp_config = config.copy()
            temp_config['preprocessing']['target_creation']['lookforward_periods'] = horizon
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π FeatureEngineer
            temp_feature_engineer = FeatureEngineer(temp_config['preprocessing'])
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º
            temp_processed = temp_feature_engineer.process_multi_timeframe(
                {'5m': data_5m, '15m': data_15m}, 
                'BTC/USDT'
            )
            
            if temp_processed is not None and 'target' in temp_processed.columns:
                temp_dist = temp_processed['target'].value_counts()
                temp_balance = temp_dist.min() / temp_dist.max()
                horizon_results[horizon] = {
                    'balance_ratio': temp_balance,
                    'class_distribution': temp_dist.to_dict(),
                    'total_samples': len(temp_processed)
                }
                logger.info(f"  –ì–æ—Ä–∏–∑–æ–Ω—Ç {horizon}: –±–∞–ª–∞–Ω—Å={temp_balance:.3f}, –æ–±—Ä–∞–∑—Ü–æ–≤={len(temp_processed)}")
        
        # 5. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–ù–´–• –ü–û–†–û–ì–û–í
        logger.info("\nüìä 5. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–ù–´–• –ü–û–†–û–ì–û–í –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
        logger.info("-" * 30)
        
        thresholds = [0.001, 0.002, 0.005, 0.01]  # 0.1%, 0.2%, 0.5%, 1%
        threshold_results = {}
        
        for threshold in thresholds:
            logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥: {threshold*100:.1f}%")
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            temp_config = config.copy()
            temp_config['preprocessing']['target_creation']['fall_threshold'] = -threshold
            temp_config['preprocessing']['target_creation']['rise_threshold'] = threshold
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π FeatureEngineer
            temp_feature_engineer = FeatureEngineer(temp_config['preprocessing'])
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
            temp_processed = temp_feature_engineer.process_multi_timeframe(
                {'5m': data_5m, '15m': data_15m}, 
                'BTC/USDT'
            )
            
            if temp_processed is not None and 'target' in temp_processed.columns:
                temp_dist = temp_processed['target'].value_counts()
                temp_balance = temp_dist.min() / temp_dist.max()
                threshold_results[threshold] = {
                    'balance_ratio': temp_balance,
                    'class_distribution': temp_dist.to_dict(),
                    'total_samples': len(temp_processed)
                }
                logger.info(f"  –ü–æ—Ä–æ–≥ {threshold*100:.1f}%: –±–∞–ª–∞–Ω—Å={temp_balance:.3f}, –æ–±—Ä–∞–∑—Ü–æ–≤={len(temp_processed)}")
        
        # 6. –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –î–ê–ù–ù–´–•
        logger.info("\n‚öñÔ∏è 6. –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –î–ê–ù–ù–´–•")
        logger.info("-" * 30)
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        balanced_data = feature_engineer.balance_data(processed_data, 'BTC/USDT')
        
        if balanced_data is not None:
            target_dist_after = balanced_data['target'].value_counts()
            logger.info(f"üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ü–û–°–õ–ï –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:")
            for class_id, count in target_dist_after.items():
                percentage = count / len(balanced_data) * 100
                logger.info(f"  –ö–ª–∞—Å—Å {class_id}: {count} ({percentage:.1f}%)")
            
            balance_ratio_after = target_dist_after.min() / target_dist_after.max()
            logger.info(f"üìä –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {balance_ratio_after:.3f}")
            
            if balance_ratio_after > 0.8:
                logger.info("‚úÖ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
            elif balance_ratio_after > 0.6:
                logger.info("‚úÖ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.")
            else:
                logger.warning("‚ö†Ô∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–ª–æ—Ö–æ.")
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            balanced_data = processed_data
        
        # 7. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø
        logger.info("\nüéì 7. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø")
        logger.info("-" * 30)
        
        X, y = feature_engineer.prepare_for_training(balanced_data, 'BTC/USDT')
        
        if X is None or y is None:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False
        
        logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X)} —Å—Ç—Ä–æ–∫, {len(X.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # 8. –í–†–ï–ú–ï–ù–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø
        logger.info("\n‚è±Ô∏è 8. –í–†–ï–ú–ï–ù–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø")
        logger.info("-" * 30)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è TimeSeriesSplit
        tscv = TimeSeriesSplit(n_splits=5, test_size=int(len(X) * 0.2))
        
        logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è TimeSeriesSplit –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
        logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤: {tscv.n_splits}")
        logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–µ—Ç–∞: {int(len(X) * 0.2)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        # 9. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ò –ê–ù–ê–õ–ò–ó –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–Ø
        logger.info("\nü§ñ 9. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ò –ê–ù–ê–õ–ò–ó –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–Ø")
        logger.info("-" * 30)
        
        # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model = AdvancedEnsembleModel(config['ml_model'])
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        train_df = X.copy()
        train_df['target'] = y
        
        success = model.train(train_df, 'BTC/USDT')
        
        if not success:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
            return False
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = model.get_model_summary()
        
        logger.info("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø:")
        val_metrics = results.get('val_metrics')
        if val_metrics is None and 'training_results' in results and 'val_metrics' in results['training_results']:
            val_metrics = results['training_results']['val_metrics']
        if val_metrics:
            logger.info(f"  –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {val_metrics['accuracy']:.4f} ({val_metrics['accuracy']*100:.2f}%)")
            logger.info(f"  F1-—Å–∫–æ—Ä: {val_metrics['f1']:.4f}")
            logger.info(f"  Precision: {val_metrics['precision']:.4f}")
            logger.info(f"  Recall: {val_metrics['recall']:.4f}")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–¥–µ–ª–∏!")
        
        # 10. CONFUSION MATRIX
        logger.info("\nüîç 10. CONFUSION MATRIX")
        logger.info("-" * 30)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º —Å–µ—Ç–µ
        if 'classifier' in model.models:
            # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/val
            split_idx = int(len(train_df) * 0.9)
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = model.models['classifier'].predict(X_val)
            
            # Confusion matrix
            cm = confusion_matrix(y_val, y_pred)
            logger.info("üìä Confusion Matrix:")
            logger.info(f"  {cm}")
            
            # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
            class_names = sorted(y.unique())
            logger.info("üîç –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö:")
            for i, true_class in enumerate(class_names):
                for j, pred_class in enumerate(class_names):
                    if i != j and cm[i, j] > 0:
                        logger.info(f"  –ö–ª–∞—Å—Å {true_class} ‚Üí –ö–ª–∞—Å—Å {pred_class}: {cm[i, j]} –æ—à–∏–±–æ–∫")
        
        # 11. –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í
        logger.info("\nüîù 11. –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í")
        logger.info("-" * 30)
        
        if 'feature_importance' in results:
            top_features = sorted(results['feature_importance'].items(), 
                                key=lambda x: x[1], reverse=True)[:15]
            logger.info("üîù –¢–æ–ø-15 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
            for i, (feature, importance) in enumerate(top_features, 1):
                logger.info(f"  {i:2d}. {feature}: {importance:.4f}")
        
        # 12. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
        logger.info("\nüí° 12. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –¢–û–ß–ù–û–°–¢–ò")
        logger.info("-" * 30)
        accuracy = None
        if val_metrics:
            accuracy = val_metrics.get('accuracy')
        if accuracy is not None:
            if accuracy < 0.60:
                logger.warning("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò –ù–ò–ó–ö–ê–Ø –¢–û–ß–ù–û–°–¢–¨!")
                logger.info("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                logger.info("  1. –£–≤–µ–ª–∏—á–∏—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–æ 12-24 —Å–≤–µ—á–µ–π")
                logger.info("  2. –°–Ω–∏–∑–∏—Ç—å –ø–æ—Ä–æ–≥–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ 0.1-0.2%")
                logger.info("  3. –£–ª—É—á—à–∏—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö")
                logger.info("  4. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                logger.info("  5. –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –º–æ–¥–µ–ª–∏")
            elif accuracy < 0.70:
                logger.warning("‚ö†Ô∏è –ù–ò–ó–ö–ê–Ø –¢–û–ß–ù–û–°–¢–¨!")
                logger.info("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                logger.info("  1. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –ø–æ—Ä–æ–≥–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                logger.info("  2. –£–ª—É—á—à–∏—Ç—å feature engineering")
                logger.info("  3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
            else:
                logger.info("‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –≤ –Ω–æ—Ä–º–µ!")
        else:
            logger.warning("‚ùì –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å accuracy –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π!")
        
        # 13. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò
        logger.info("\nüíæ 13. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
        logger.info("-" * 30)
        
        diagnostic_results = {
            'original_balance_ratio': balance_ratio,
            'balanced_balance_ratio': balance_ratio_after if balanced_data is not None else balance_ratio,
            'horizon_results': horizon_results,
            'threshold_results': threshold_results,
            'model_accuracy': accuracy,
            'class_distribution_before': target_dist_before.to_dict(),
            'class_distribution_after': target_dist_after.to_dict() if balanced_data is not None else target_dist_before.to_dict(),
            'recommendations': []
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if accuracy < 0.60:
            diagnostic_results['recommendations'].extend([
                '–£–≤–µ–ª–∏—á–∏—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è',
                '–°–Ω–∏–∑–∏—Ç—å –ø–æ—Ä–æ–≥–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏',
                '–£–ª—É—á—à–∏—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö'
            ])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        import json
        with open('diagnostic_results.json', 'w', encoding='utf-8') as f:
            json.dump(diagnostic_results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ diagnostic_results.json")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    success = diagnose_accuracy_issues()
    if success:
        logger.info("\n‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    else:
        logger.error("\n‚ùå –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏!") 